{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hlZxoYr6PXdR"
   },
   "source": [
    "In this file we train an LSTM based Deep Learning model using the Document Embeddings obtained from the training of the Summary Text using FastText API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ciLY49_dBQIt"
   },
   "outputs": [],
   "source": [
    "# load cleaned data file (adm_ds2.csv) which is obtained after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27121,
     "status": "ok",
     "timestamp": 1596331344222,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "IeNJqXQNBV6y",
    "outputId": "cdfb4ac7-32a3-46f6-cf63-099f58c2e464"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import os, sys, math, csv, datetime, time, pickle, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtSe1aCjBiPW"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bLKaHLMD0mAw"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zP5CFT2aBY5a"
   },
   "outputs": [],
   "source": [
    "## load csv into a dataframe\n",
    "df = pd.read_csv('adm_ds2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HFFHQ1DCY0G"
   },
   "outputs": [],
   "source": [
    "# split the dataset into train and test as 80-20 % respectively\n",
    "train_x, test_x, train_y, test_y = train_test_split(df.cleaned_text, df.TARGET, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1235,
     "status": "ok",
     "timestamp": 1596331989478,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "y_xErffYCg1z",
    "outputId": "2c8569a8-92ca-43c2-d332-95f37ae1c434"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42180,), (10546,), (42180,), (10546,))"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "siZZtynTxKvh"
   },
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 936,
     "status": "ok",
     "timestamp": 1596331994247,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "JvJO1u03oDNU",
    "outputId": "9fa385f8-33db-433f-e0b1-114c974123b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([40353,  1827]))"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPx2OTK4QJpY"
   },
   "outputs": [],
   "source": [
    "# from here the downsampling process starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7XHASTQky-uV"
   },
   "outputs": [],
   "source": [
    "## separate the train data with target == 1 and target == 0\n",
    "train0x = train_x[train_y == 0]\n",
    "train1x = train_x[train_y == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1598,
     "status": "ok",
     "timestamp": 1596332002971,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "14_5lHVooauI",
    "outputId": "d7e314bb-1185-4c7b-b5a9-84d1be24be46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40353,), (1827,))"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train0x.shape, train1x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kcBzSQ2jocu1"
   },
   "outputs": [],
   "source": [
    "## get the 3 times the data for the majority class to downsample it\n",
    "## get the data in shuffled form only\n",
    "indices = np.random.choice(np.arange(train0x.shape[0]), 3*train1x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MyLGcemKxSAD"
   },
   "outputs": [],
   "source": [
    "# load train vectos for summary features\n",
    "!cp /content/drive/My\\ Drive/train_vectors_cleaned_text_cbow.pkl ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9eH-ENxjxl9A"
   },
   "outputs": [],
   "source": [
    "## load train vectors from pickled file\n",
    "with open('train_vectors_cleaned_text_cbow.pkl', 'rb') as fin:\n",
    "    train_vectors = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gmE8ukNvx6Rs"
   },
   "outputs": [],
   "source": [
    "## get the train data feature vectors for the above downsampled shuffled indices\n",
    "train_x_vectors_0 = train_vectors[train_y == 0][indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1518,
     "status": "ok",
     "timestamp": 1596331819203,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "54HbIjnrygwn",
    "outputId": "348a843b-49b1-48d2-a150-3e116271097b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5481, 100), (5481,))"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_vectors_0.shape, indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o_-ARDfHykrA"
   },
   "outputs": [],
   "source": [
    "## get the train data feature vectors for the minority class\n",
    "train_x_vectors_1 = train_vectors[train_y == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DaZWmDI5yuKX"
   },
   "outputs": [],
   "source": [
    "## combine the downsampled majority class and all minority class feature vectors\n",
    "train_x_vectors = np.concatenate([train_x_vectors_0, train_x_vectors_1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1381,
     "status": "ok",
     "timestamp": 1596331880354,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "dap59QWUy1Kj",
    "outputId": "fc9fa864-4600-49c6-8cc9-ec67894d60c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7308, 100)"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TvxsvknPzhUj"
   },
   "outputs": [],
   "source": [
    "## get the corresponding target data values for classifier process\n",
    "sub_train_y = np.concatenate([[0]*train_x_vectors_0.shape[0], [1]*train_x_vectors_1.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1369,
     "status": "ok",
     "timestamp": 1596332118581,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "zLTJ2RbOzu96",
    "outputId": "5ab97fc9-6b27-4e8e-a61b-95b4880062f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7308,)"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d311Q_GEYiHG"
   },
   "outputs": [],
   "source": [
    "## we train the NaiveBayes Model, XGBoostClassifier\n",
    "## Deep Learning model on downsampled dataset\n",
    "## get the AUROC score on the test dataset for each of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tMwQvETJwxae"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rMryjQ9Xw9KB"
   },
   "outputs": [],
   "source": [
    "## get the Naive Bayes classifier\n",
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1128,
     "status": "ok",
     "timestamp": 1596332035102,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "4MseHEiTzlNE",
    "outputId": "9fcf0444-4f27-437c-f1b2-de866141623a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42180, 100)"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_vectors).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1089,
     "status": "ok",
     "timestamp": 1596332126993,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "AcbqStZCw_y-",
    "outputId": "5d9d0448-f816-4436-f5fd-9c584741e802"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train the Naive Bayes classifier on the above train data feature vectors\n",
    "nb.fit(train_x_vectors, sub_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R3r6wGiVz0Bs"
   },
   "outputs": [],
   "source": [
    "## load the test data feature vectors\n",
    "!cp /content/drive/My\\ Drive/test_vectors_cleaned_text_cbow.pkl ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMVieTEMz5aC"
   },
   "outputs": [],
   "source": [
    "## load the test data feature vectors from its pickled file\n",
    "with open('test_vectors_cleaned_text_cbow.pkl', 'rb') as fin:\n",
    "    test_vectors = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PN1vjqd90YO6"
   },
   "outputs": [],
   "source": [
    "## get the probability for all the test data feature vectors\n",
    "nb_preds = nb.predict_proba(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1656,
     "status": "ok",
     "timestamp": 1596332362767,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "OF5rj2UY0kkz",
    "outputId": "d240ebd9-53c5-43c7-b761-0467341af77b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6215899128147678"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get the auroc score\n",
    "roc_auc_score(test_y, nb_preds[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkQI0LYQo5fP"
   },
   "source": [
    "The AUROC score we get for the Naive Bayes classifier is *0.6215899128147678* \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Lets compare the score with further classification process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVU7axP13gSo"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b31GCao64-Ra"
   },
   "outputs": [],
   "source": [
    "## load the XGBoost classifier\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6585,
     "status": "ok",
     "timestamp": 1596332393676,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "aKA_ncaI5BvG",
    "outputId": "8095a9d4-b3cd-46cb-b528-9cc6d5f955fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train teh feature vectors on XGBoost Classifier\n",
    "xgb.fit(train_x_vectors, sub_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1280,
     "status": "ok",
     "timestamp": 1596332433718,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "HdagB_ey04O_",
    "outputId": "979a328f-5af3-42d5-a51a-3c83bef0613d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6690616222622702"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get the auroc score on the test dataset for the xgboost classifier\n",
    "roc_auc_score(test_y, xgb.predict_proba(test_vectors)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1339,
     "status": "ok",
     "timestamp": 1596332454038,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "LfUa4N9WRmo3",
    "outputId": "dd88e5df-7838-4d00-f60b-8fa64a799b29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb800d23ef0>"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEDCAYAAAAcI05xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXRb533m8e8PAAlu4E6RlEiJkixL3jd5TeJ6SduM4zhtpmndNJm0zamne9OmS3I6k57pdDqdTJtJk7RpPGky7WnUrE7juG28yk680ZFlS15kyVopipS4byBBAsQ7fwCUIYoUSYnAxQWezzk8uLjYfpeGH71873vf15xziIhI/gp4XYCIiJybglpEJM8pqEVE8pyCWkQkzymoRUTynIJaRCTPZS2ozezLZtZnZq+u0vvNmtnL6Z8HV+M9RUT8wLI1jtrMbgUmgH90zl2+Cu834ZyruvDKRET8JWstaufcD4ChzH1mttnMvm9mL5rZD81sW7Y+X0SkUOS6j/p+4Lecc9cBvw/87QpeW2Zmu8zseTP7qeyUJyKSf0K5+iAzqwJuAb5pZnO7w+nH3gf86QIvO+Gc+8n09gbn3Akz2wQ8YWavOOcOZbtuERGv5SyoSbXeR5xzV89/wDn3APDAuV7snDuRvj1sZk8C1wAKahEpeDnr+nDOjQFHzOz9AJZy1XJea2Z1ZjbX+m4E3ga8nrViRUTySDaH5/0z8Byw1cy6zewjwC8AHzGzPcBrwHuX+XaXALvSr9sJ/IVzTkEtIkUha8PzRERkdejKRBGRPJeVk4mNjY2uo6MjG28tIlKQXnzxxQHnXNNCj2UlqDs6Oti1a1c23lpEpCCZ2bHFHlPXh4hInlNQi4jkOQW1iEieU1CLiOQ5BbWISJ5TUIuI5DkFtYhInlNQi4jkuVxOc1qQkknHY/tO8eCeHna+0cdl62r4tR/bzG1bm8iYd1tE5LwpqC/QB/++k2cPDVJRGmRrc4T9J8f5pf/3I27cWM8//PINlJUEvS5RRHxOQX0BnnjjFM8eGuTGjfXcfeVaggFjNulwOD753df4xAOv8OmfvUotaxG5IArq89Q3HuMPvrmXluoy7rqilWAgFcbBgPGBGzcwMhnn048e4NLWan7l1k0eVysifqagPk//5TuvMjGd4Fd/bDMlwTPPye7o7KKhspTL11bz5/+2j8HoDOvrK/jAjes9qlZE/EyjPs7DiZEpHt13iv986yaaq8sWfI6Z8R+va6MyHOLh106iBRpE5HwpqM/DAy924xy8f3v7OZ8XDgW5fWsTRwaiHOybyFF1IlJo1PWxTDs6uwBwzvGVZ4+yqbGSH745sOTrrt9Yz9MHB3jk9VN88j2X6sSiiKyYWtQrdHRwkqHoDNduqFvW80OBAHdua+bEyBT//urJLFcnIoVIQb1Cu48NUxoKcPnammW/5ur1tTRWhfniDw5nsTIRKVQK6hWYSSR55cQoV6yroTS0/F9dwIwbNtaz5/gIB06NZ7FCESlECuoVONQ/wcxskqvba1f82qvbawkFjG/uOp6FykSkkCmoV+Bw/wShgLG+vmLFr60Kh3jnJc1856UTxGeTWahORAqVgnoFjgxGaa+vOOsCl+X62evbGJiYYecbfatcmYgUMgX1Mk3NzNI7EmNjY+V5v8etW5pYEwnzjV3dq1iZiBQ6BfUyHRuM4oBNFxDUoWCA913bxs79fQxFZ1avOBEpaArqZToyECUUMNrPo386011XtDCbdDy5X90fIrI8ujJxmQ4PRGmrO//+aUhd3Zh0juqyEF9++gixeOqkoiZrEpFzUYt6GcZjcXpGptjUdP7dHnMCZmxtqeZA3wQJjf4QkWVQUC/DrqPDOLigE4mZLmmNMJNIcmQguirvJyKFbVlBbWa/a2avmdmrZvbPZrbw3J4F6vkjgwQDRnvdhfVPz9ncVEVJ0Nh3cmxV3k9ECtuSQW1m64DfBrY75y4HgsC92S4sn7x6YpSW6rIVXTZ+LiXBABetifBG77jmqRaRJS03eUJAuZmFgAqgJ3sl5RfnHPt6x2mtWd0/Ii5piTAyFefkWGxV31dECs+SQe2cOwH8JdAF9AKjzrlH5j/PzO4zs11mtqu/v3/1K/VI/8Q0Q9EZWlY5qLe2RDBgX68maRKRc1tO10cd8F5gI7AWqDSzD85/nnPufufcdufc9qamptWv1CNvpIO0ZZElt85XpKyEdXXlmk1PRJa0nK6PdwJHnHP9zrk48ABwS3bLyh9vpE/4rXZQA1zcHOH40CTDukpRRM5hOUHdBdxkZhWWWkfqTmBfdsvKH/t6x2mpLqMivPrXBm1tjuCAH7xZOF1FIrL6ltNH3Ql8C9gNvJJ+zf1Zritv7OsdY1trJCvvva6unMrSIE/uV1CLyOKW1Ux0zv0J8CdZriXvzCSSHOqf4PZta7Ly/gEztjRHeOpAP7NJRzCghW9F5Gy6MvEcDg9MEJ91bGvJTosaUt0fQ9EZ9naPZO0zRMTfFNTnMDfi45LW6qx9xpY1VQQMdqr7Q0QWoaA+h329Y5QGA6s2x8dCKsIhrllfx1Oa9lREFqGgPod9J8e5aE3VBU1tuhy3b21iT/co/ePTWf0cEfEnBfU5vJHFER+ZbtuaOln5gwPq/hCRsymoFzE6FadvfJqLm7Mf1JetrWZNJMxOdX+IyAK0wss8Ozq7ADgxPAXA8aHJ0/uyxcy4bWsT33/1JInZJKEsd7WIiL8oqBcxGE31F9dXlmb9s3Z0dhEMBBiLJfjU9/fTkT55qSW6RATU9bGouVXCGyrDOfm8uWF6+zVJk4jMo6BexODEDJFwaNUWC1hKWUmQDQ2Vmk1PRM6ioF7EYHSa+qrsd3tk2tocoXc0xuhUPKefKyL5TUG9iKHoTM66PeZsaa4C4FDfRE4/V0Tym4J6ATOJJGOxRE5OJGZqri6jsjTIoX4FtYi8RUG9gKHJ9InEHHd9BMzY1FTF4YGoFr0VkdMU1AsYmkgNzWvIcYsaYFNTJaNTcQa16ouIpCmoFzCY46F5mTY3pfup1f0hImkK6gUMRmcoLwlSXhrM+Wc3VJZSU17Cof5ozj9bRPKTgnoBQ9GZnPdPzzEzNjdVcrh/gmRS/dQioqBe0ODEdM5HfGTa1FTF5MysrlIUEUBBfZZEMsnIZNyTE4lzNqXn+nj20KBnNYhI/lBQzzMyGcfhzYnEObUVpTRUlvL8YQW1iCiozzI3GZOXXR8A6+sreKlrROOpRURBPd/c0Lxcz/MxX3t9BQMT03Sn58UWkeKloJ5ndHKGYMCoCns7Vff6+goAdncNe1qHiHhPQT3PyFScmvISAmae1tFcXUZ5SZCXukY8rUNEvKegnmd0MhXUXgsGjCvbanjpuIJapNgpqOcZnYpTmwdBDXDthjpe7xklFp/1uhQR8ZCCOsNs0jEWy48WNcA17bXEZx2v9Yx6XYqIeEhBnaFvPEbSQU1FngT1+joA9VOLFDkFdYaekRhA3nR9NEXCtNeXa+SHSJFTUGfoGUmNWa6p8HYMdaZr2uvUohYpcgrqDL2jqaDOlxb1js4uks7ROxrjC08eYkdnl9cliYgHFNQZekZihEMBykpyPw/1YtrrUhe+dA1NelyJiHhFQZ2hZ2Qqb0Z8zGmtLSMUMI4rqEWKloI6Q8/oFLV5MuJjTigQYG1tuYJapIgpqDP0jsSoKc+fE4lz1tdXcGJkikQy6XUpIuIBBXVaLD7LYHQm77o+IDWTXiLpODka87oUEfHAsoLazGrN7Ftm9oaZ7TOzm7NdWK71pkMw37o+4K2Z9HRCUaQ4LXcuz78Gvu+c+xkzKwUqsliTJ06Poc7DFnVNeQnVZSEFtUiRWjKozawGuBX4RQDn3Awwk92ycm8uqPNlDPV86+srdEJRpEgtp+tjI9APfMXMXjKzL5lZZZbryrm5y8fzsUUNqX7q4ck4/ePTXpciIjm2nKAOAdcCX3DOXQNEgY/Pf5KZ3Wdmu8xsV39//yqXmX29o1M0VoUJBfPz/OpcP/VLmvdDpOgsJ5W6gW7nXGf6/rdIBfcZnHP3O+e2O+e2NzU1rWaNOXFiZIq1tWVel7GotbXlBAPGrmMKapFis2RQO+dOAsfNbGt6153A61mtygMnR2O01uRvUJcEA7TVldN5ZMjrUkQkx5b7d/5vAV81s73A1cCfZ68kb6SCutzrMs5pY2Mlr54YZWI64XUpIpJDywpq59zL6W6NK51zP+WcK6i/vyemE4xPJ2jJ4xY1wMaGSmaTjt3q/hApKvl55izH5q74a6nO76Be31BBMGB0Hhn0uhQRySEFNRlBnect6nAoyBXraug8rH5qkWKioOatBQPy+WTinBs31bOne0Qrk4sUEQU1cGos1aJuzvOuD4AbN9YTn3VaR1GkiCioSU3IVFdRklcruyxme0c9AUPdHyJFREFNqo+6Jc+H5s2pLivh0rXVOqEoUkQU1MDJsRgt1WGvy1i2WzY3svvYCFGNpxYpCgpq/NWiBvixi5uYmU3y3CG1qkWKQdEH9XQitbKLH0Z8zNneUUdFaZAnD/R5XYqI5EDRB3XfWGra0Hy/2CVTOBTkls2NPLm/H+ec1+WISJYVfVD3+uRil/lu29pE9/AUhweiXpciIlm23KW4CtKOzi72dI8A8OKxYbqHpzyuaGk7OrsAGJ2MA/DpRw7wtosa+cCN670sS0SyqOhb1GNTqcDL15VdFlNXWUpTVZgDp8a9LkVEsqzog3p0Kk5pKEA45L9fxcXNVRwZiDKTSHpdiohkkf/SaZWNTcWpLivBzLwuZcUubomQSDoOD0x4XYqIZFHRB/XoVJyacn921Xc0VFISNA6cUlCLFLKiD+qxWMJ3/dNzSoIBNjVWqZ9apMAVdVAnnWM8lur68KuLWyIMRWc4omF6IgXLn3/z89YwtUwrHaI2EUuQdFDt0xY1wNbmCN8Dntzfx8bGjV6XIyJZUNQt6lGfDs3LVF9ZSmNVKU8d6Pe6FBHJkqIO6pF0UNdW+DeoAbY0R3ju0KBWfREpUEUd1KOTMwDUlpd6XMmF2docYTqR5PnDmk1PpBAVdVCPTMUpDQYoK/H3r2FjYyXhUIAn96v7Q6QQ+TuhLtDoVJyaCn9e7JKpJBjgls0N7Nzfp9n0RApQUQf1yGScWh+fSMx0x7Y1HBuc1Gx6IgWouIN6Ku77E4lzbt+2BoCdb2gxAZFCU7RBHYvPEp1OUOPzE4lz2uoquLi5iicU1CIFp2iDem7BgEJpUUOqVf3CkSHGY3GvSxGRVVS0Qd0zklokoFD6qAHu2LqGRNLx9JsDXpciIqvIt5eQX6gTc0FdURhdHzs6u5hNOspKAnzph0cYTq8Ao5VfRPyvqFvUBlSXFc6/VcGAsWVNhP2nxklqmJ5IwSjqoK4qCxEKFtavYFtLhInpxOmuHRHxv8JKqRXoGYkVVP/0nC3NEQzYf1JzVIsUiuIN6tEpagqkfzpTVThEW105+7WYgEjBKMqgds7RMzJVkC1qgK0t1XQPT2mYnkiBKMqgHp6ME4snfT0P9blsa4kAaC1FkQJRlEF9egx1AV3skqm1pozqshD7T455XYqIrIJlB7WZBc3sJTN7KJsF5cLpMdQFcvn4fGbGxc0R3uybID6b9LocEblAK2lR/w6wL1uF5NJci7qmQFvUkOr+mE4k+dHRIa9LEZELtKygNrM24N3Al7JbTm70jEwRDgWoLA16XUrWbF5TRTBgPLFPkzSJ+N1yW9SfAf4QKIi/o7uGJmmrK/f9ggHnEg4F2dRYyeOaTU/E95YMajO7G+hzzr24xPPuM7NdZrarvz+/l4Q6OjDJxsZKr8vIum2t1RwZiHKoX6M/RPxsOS3qtwH3mNlR4GvAHWb2T/Of5Jy73zm33Tm3vampaZXLXD3JpOPoYJSOhiII6vQwvcf3nfK4EhG5EEsGtXPuE865NudcB3Av8IRz7oNZryxLTo7FmE4k6SiCFnVdRSnbWiI8pn5qEV8runHUR9NrChZD1wfAOy9p5sVjw4xMznhdioicpxUFtXPuSefc3dkqJheODk4CFEWLGuDOS9Ywm3Q8uT+/zxuIyOKKr0U9GKU0FKC1uszrUnLiqrZaGqvCPKZ+ahHfKrqgPjIQZUN9BYFA4Q7NyxQIGHduW8NTB/p1laKITxVdUB8diBZNt8ecOy9Zw3gswY+O6CpFET8qqqBOJh3HhopjDPWcHZ1d9IzECAWMv9l5kB2dXV6XJCIr5Ougnk26Fa0N2DM6xUwiWRRjqDOVhgJsbqpi38lxnNZSFPEd367s6pzj/zx2gJHJGarCIbY0R5ZccfvY6REfFbkoMa9sa42w/+Vx+sanvS5FRFbIty3q6USSoegMGxsrqa0oZfexYaLTiXO+5kiRjaHOtK2lGoA3tJaiiO/4NqjH0stMXbehnlu3NOGAA0usE3h0IEo4FKA5UhxD8zLVlJewtqaMN3q1mICI3/g2qMdjqdZzpCxES00qeJdqLc7N8VEsQ/Pm29ZaTdfQJENRXaUo4ic+DupUi7q6rITaihLCocCSrcUjA9Gi7J+ec2lrNQ54+LWTXpciIivg46B+q0UdMKO5uox952hRx2eTHB+aKrox1Jlaa8porCrlwZd7vC5FRFbA10FdEjTCodQhtKT7Xxcbfnbg1Dgzs0kuW1uTyzLziplxVVstzx8Z5ORozOtyRGSZfBvUY7E4kbKS06u0tFSXMRZL0LtIAO05PgrAVW3FG9SQmvvDOXhor1rVIn7h26AejyWoLntrGHjr6ROKZ/dT7+js4oHd3ZSXBHn6zQF2dHYV7RV6jZEwl6+r5nt7FNQifuHjoE61qOc0p2fD29e7cD/1iZGpgl8ncbnuuWote7pHT8/NLSL5zcdBnSCS0aIuKwnSVle+4BC9mUSSU2Mx1tWV57LEvHX3lWsBeFCtahFf8GVQR6cTTCeSZ7SoIXX13UJD9HpHp0g6aKst3qF5mdbWlvO2ixr42gtdJDT1qUje82VQz81XkdlHDXBJa4TDA1Fi8dkz9ncPTwHQVq8W9ZwP39xBz2iMR1/XggIi+c6fQT2WGtmxUIt6Nuk42Ddxxv7u4Umqy0JUz3t+Mbvzkmba6sr5yrNHvS5FRJbgz6BOt6gj81rUV6xLDb17/vDgGfu7h6doq1O3R6ZgwPjwzR28cGSI13s0/4dIPvNlUJ863aI+M6jXN1Rw2dozh56NTsYZjM7QphOJp80NTwyYURI0PvndV4t2uKKIH/gyqPvHpwkFjPKS4FmPzR96tvfECIBGfCygvDTINe11vHx8hIklpogVEe/4Mqj7xqeJlIUWHBN991WpoWff29ODc44v/fAI4VCAdnV9LOiWixpIJB2d87qLRCR/+HKFl77x2FknEuesqy3n+o46HtzTw9aWCE8d6OeuK1opW6D1LbAmUsa2lgjPHR4kFp/V70kkD/myRX1qbPqs/ulM91y1ljf7Jvijb+/l4uYqbt7UkMPq/OcdW5qYnJnl27u7vS5FRBbgy6DuG1u8RQ1w1xWtBAPG8GScP33v5QSLdKGA5epoqKCtrpwv/fAIyaQWvxXJN74L6lh8lrF5EzLN11AV5t7r2/nFWzq4Sa3pJZkZb7+okSMDUR7bpwtgRPKN7/qo+xcZQz3f//jpK3JRTsG4bG0Na2v6+YfnjvITl7V4XY6IZPBdi7pvfOGrEuXCBAPGL9y0gWcODp51ZaeIeMt3QX1qbHktalm5n7u+ndJggH96/pjXpYhIBt8F9eBEKqirwgrq1dZYFeauK1r49ovdRHUBjEje8F1QD0+mVh+vKFVQZ8OHbu5gfDrBd1464XUpIpLmu7Qbis4QKQtpyF0W7OjswjnH2poyPvfEmxipESEfuHG916WJFDUftqhnqK8s9bqMgmVm3LSpgVNj0xwdnPS6HBHBh0E9FJ2hrkJBnU1XttVSXhI8a7pYEfGG74JaLersKw0FuG5DHa/1jDI2Ffe6HJGi57s+6uFonIubIws+pjmVV8+NG+t55uAALxwd4lfZ7HU5IkXNny1qdX1kXUNVmC3NVfzo6BBxLYAr4qklg9rM2s1sp5m9bmavmdnv5KKwhcTis0zOzFKnro+cuGlTA+OxBA+/dtLrUkSK2nJa1AngY865S4GbgN8ws0uzW9bChidnANRHnSMXN0eoqyjRlYoiHlsyqJ1zvc653entcWAfsC7bhS1kOJo6sVVXoXk+ciFgxg0bG3j+8BAH+8a9LkekaK2oj9rMOoBrgM4FHrvPzHaZ2a7+/v7VqW6euRa1huflznUb6tLzf+hErYhXlh3UZlYFfBv4qHNubP7jzrn7nXPbnXPbm5qaVrPG04ai6vrItapwSPN/iHhsWUFtZiWkQvqrzrkHslvS4k63qBXUOfWhmzcwPp3guy/3eF2KSFFazqgPA/4e2Oec+3T2S1rcXIu6tlx91Ll07fo6Lm2t5ivPHME5LdUlkmvLaVG/DfgQcIeZvZz+uSvLdS1oZDJOdVmIUNB3w799zcz4yNs38mbfBE8dyM75BxFZ3JJXJjrnngbyYqq6oaguH/fCjs4uEskkkbIQf/av++gZiWlGPZEc8lXTdHhyRv3THgkFAty8qYGDfRP0jk55XY5IUfFVUA9Fdfm4l27YWE9J0HjmoGbVE8klXwX1yGScWgW1ZypKQ1y3oZ49x0c4Nhj1uhyRouGroE71UWvEh5duu7iJQAA+9fB+r0sRKRq+CeqpmVmm4pqQyWvV5SW8Y0sT/7q3lxePDXtdjkhR8E1Qn56QSV0fnnvHlkaaImH+/N/2aVy1SA74JqhPX+yioPZcOBTkYz9+MS8eG+bBPbpaUSTbfBPUI5OpmfM0jjo/vH97O1e31/Jf/+VVDdcTyTLfBPXQ6bmodTIxHwQDxmd+7moSScfHvrGHZFJdICLZ4pugHo5qitN809FYyZ+851KePTTI3z99xOtyRAqWbxa3neujrtGETHlhbiFh5xyXtlbzP/99H6fGY/yXd3uy+I9IQfNNi3pkcoaa8hJNyJRnzIyfua6N+sowOzq76B6e9LokkYLjm9QbmozrRGKeKisJ8qGbNjCbdNz3jy8yOaMFBkRWk2+Cejg6o7US81hTJMy917fzxskxfuOru4nPJr0uSaRg+Caoe0enWBMp87oMOYetLdX82U9dwc79/XzigVd0MYzIKvHFycRk0tE9PMUd29Z4XYos4QM3rufkWIzPPv4mTZEwf/SubV6XJOJ7vgjq/olpphNJ1tdXeF2KLGFHZxfNkTA3dNTzhScPcbBvgtu3rtFCAyIXwBdBfXwoNZKgTUHtC2bGPVevJT6b5NHXT1EaDCioRS6AL/qou9JBrRa1fwTMeN+1bVy+tpp/faX39LhrEVk5XwT18aHUXBLrass9rkRWIhgwfvb6drY2R/jjf3mF77zU7XVJIr7ki6DuGpqkpbqMspKg16XICoUCqW6Pmzc18LFv7NFseyLnwRdBfXx4kvZ6tab9qiQY4P/+p+1s76jno197iW/uOu51SSK+4oug7h6apF3907723Zd7uOvyVjY1VfEH39rLb+7YrXHWIsuU90E9nZildyxGe52C2u9KQwE+dNMGLmmt5qG9vfz+N/cyNTPrdVkieS/vg7pnJIZzGvFRKEqCAX7hxvXcsW0ND7zUzfu+8Cz7T457XZZIXsv7oJ4bmqeuj8IRMOOdlzTz5Q9fT99YjLs/90M++/ibmh9EZBF5H9THNYa6YN2+bQ2P/O6tvOvyVj796AHu+fwzvHpi1OuyRPKOL4K6NBRgTSTsdSmyynZ0dvHwa6e4eVMDH7xxPceHJrnn80/zV4/sZzqhvmuROfkf1MOTtNWVEwiY16VIFl26toaPvnMLV7XV8rknDvKezz3NnuMjXpclkhfyPqi7hiY14qNIVJSGeP/2dr78i9sZm0rw03/7DL/3jZd585RONkpxy/tJmY4PTXFNe53XZUgOnRyd5r5bN/H4vlN8b08PD+w+wcXNVfzKOzbxE5e2UKMFJKTI5HVQj07FGZ2K66rEIlRWEuTdV67ltq1reO7wIC91DfMH39rLxwOvcFVbDbdsbuSWzQ1cu6FOUwtIwcvroN7dNQzA5qYqjysRr1SGQ7zzkmbu3LaG7uEpXu8d43D/BH+z8yCf33mQUMC4vqOeWzY3cMtFDVzZVkuJFkCWApPXQf31F45TX1nK27c0el2KeMzMaK+vOD2ePhaf5ehAlEP9ExweiPLc4UH+6lEoDQboaKzggzdt4D1XrqVOCyJLAcjboO4fn+axfaf4pbd1EA7pT1s5U1lJkG2t1WxrrQYgOp3g8ECUw/0THOqf4JPffY3//tDr3L51DT9xWQu3b22ioUpDPMWf8jaov727m0TS8XPXa2UQWVplOMQV62q4Yl0NAFe31/LA7m6+t7eHR14/hVmqC21bS4RNjZXUVZZSV1FKbUUJdRWp7ZqKEiLhkIaCSt7Jy6B2zvH1Hx3nho56Llqj/mlZuZePj7CpqYrfvmMLPaMx9p8c48RIjGcODvDQ3t5FXxcwqCkvobailMaqUpqry1hbW876+go6GirZ0FDB2tpyggpzyaFlBbWZvQv4ayAIfMk59xfZLOq5w4McGYjym7dflM2PkSJgZqyrLT9jdaCkc0zNzDI5M8vkTILJmdnU/fgsU+n7kzOzDEzMcLg/yuhUnETyrSlZS4Kp/vKOhkrW1ZZTEQ5SFgpSXhqkvCRIVThEYyRMU1WYxkgpDZXhCwp25xwT04n0ZwcoDQbU6i8ySwa1mQWBvwF+HOgGfmRmDzrnXl/tYvrGY9z/1GH+qfMY9ZWl3HVF62p/hAgBMyrDISrDIWDpfuukc4zHEgxOTDMYnWFwYobB6DT7esd47tAg8dnkGUF+9udBfWUpjVVhmk4HeCq8k0lH0jlmk5BIJhlLD0kdmYozOpm+nYozm/H+oYDRFAmzJhJmTXVZ6jZSRnN1mIaqMJWlQcpKg8wmU/8gTcVnicVnmY6n6pxNzt2m3jMcChAOBQmXvHVbNu82FDAMw4z0j2GktgPpbQwMIzDvcbP060htB9LPM3vrv0fm4/P/CTKbf7/4/pFaTov6BuCgc+4wgJl9DXgvsKpBPRaLc8dfPv2BTYcAAAVeSURBVMXkTIKfvqaN377zIspLdRJRvBcwo6a8hJryEjY1LfycpHMkZh0zs0li8VkmYgkmphOMTydOb0/E4hwdiPLKiVGi0wmSyYygS9+WlQSoKA1RXhqkMhyiKRI+3VIHSCYdsUSS8ViC8VicV7pHGYvFmdS83qedFexnPW5LPD7/9ed+w8y7jVVhnvn4Hcspc0WWE9TrgMy1k7qBG+c/yczuA+5L350ws/3nW9Sn0z9LaAQGzvcz8lwhHxvo+PxOx7eIA4B94rw/d8NiD6zayUTn3P3A/av1fksxs13Oue25+rxcKuRjAx2f3+n4cm85l3CdANoz7rel94mISA4sJ6h/BGwxs41mVgrcCzyY3bJERGTOkl0fzrmEmf0m8DCp4Xlfds69lvXKlpazbhYPFPKxgY7P73R8OWbOLT6sSEREvKdpxkRE8pyCWkQkz/kuqM3sXWa238wOmtnHva7nXMzsy2bWZ2avZuyrN7NHzezN9G1der+Z2WfTx7XXzK7NeM2H089/08w+nLH/OjN7Jf2az1oOL9kys3Yz22lmr5vZa2b2OwV2fGVm9oKZ7Ukf339L799oZp3pmr6ePsGOmYXT9w+mH+/IeK9PpPfvN7OfzNjv+XfZzIJm9pKZPZS+XzDHZ2ZH09+fl81sV3qfP7+fzjnf/JA6mXkI2ASUAnuAS72u6xz13gpcC7yase9TwMfT2x8H/ld6+y7g30ld6HQT0JneXw8cTt/Wpbfr0o+9kH6upV/7H3J4bK3AtentCKmx/pcW0PEZUJXeLgE607V8A7g3vf/vgF9Lb/868Hfp7XuBr6e3L01/T8PAxvT3N5gv32Xg94AdwEPp+wVzfMBRoHHePl9+P3P6pViFX/zNwMMZ9z8BfMLrupaouYMzg3o/0JrebgX2p7e/CPz8/OcBPw98MWP/F9P7WoE3Mvaf8TwPjvO7pOaDKbjjAyqA3aSuyB0AQvO/j6RGRd2c3g6ln2fzv6Nzz8uH7zKpayIeB+4AHkrXW0jHd5Szg9qX30+/dX0sdDn7Oo9qOV/Nzrm5eTZPAs3p7cWO7Vz7uxfYn3PpP4OvIdXqLJjjS3cLvAz0AY+SaiGOOOcSC9R0+jjSj48CDaz8uHPpM8AfAsn0/QYK6/gc8IiZvWipKS7Ap9/PvJyPulg455yZ+Xp8pJlVAd8GPuqcG8vspvP78TnnZoGrzawW+A6wzeOSVo2Z3Q30OedeNLPbvK4nS97unDthZmuAR83sjcwH/fT99FuLuhAuZz9lZq0A6du+9P7Fju1c+9sW2J8zZlZCKqS/6px7IL27YI5vjnNuBNhJ6s/5WjOba+Bk1nT6ONKP1wCDrPy4c+VtwD1mdhT4Gqnuj7+mcI4P59yJ9G0fqX9ob8Cv389c9hmtQp9TiFRn/kbeOkFxmdd1LVFzB2f2Uf9vzjyZ8an09rs582TGC+n99cARUicy6tLb9enH5p/MuCuHx2XAPwKfmbe/UI6vCahNb5cDPwTuBr7JmSfbfj29/RucebLtG+ntyzjzZNthUifa8ua7DNzGWycTC+L4gEogkrH9LPAuv34/c/6lWIX/AHeRGmFwCPhjr+tZotZ/BnqBOKk+rI+Q6td7HHgTeCzjP7qRWqDhEPAKsD3jfX4ZOJj++aWM/duBV9Ov+TzpK01zdGxvJ9UHuBd4Of1zVwEd35XAS+njexX4ZHr/pvT/oAfToRZO7y9L3z+YfnxTxnv9cfoY9pMxMiBfvsucGdQFcXzp49iT/nlt7vP9+v3UJeQiInnOb33UIiJFR0EtIpLnFNQiInlOQS0ikucU1CIieU5BLSKS5xTUIiJ57v8DmRoHCWeVf6oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## plot the length distribution for the current train dataset\n",
    "sns.distplot([len(x) for x in train_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JOkB8Z40Rvpc"
   },
   "outputs": [],
   "source": [
    "## get the words in the train dataset\n",
    "words_train_x = [x.split() for x in train_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVwqnGf5TQAl"
   },
   "outputs": [],
   "source": [
    "## convert it to numpy array\n",
    "words_train_x = np.array(words_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13934,
     "status": "ok",
     "timestamp": 1596332487599,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "b6lHL4VsT6su",
    "outputId": "a2ac4202-1eb0-41be-b9ca-4dd195414137"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb6d8dd5b00>"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## plot the number of the words distribution graph for the train dataset\n",
    "sns.distplot([len(x) for x in words_train_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XAnuipOnahbb"
   },
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zTaE-d5IyXBY"
   },
   "outputs": [],
   "source": [
    "## prepare the train dataset for training of the Deep Learning model LSTM\n",
    "train_vectors_lstm = np.expand_dims(train_x_vectors, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 770,
     "status": "ok",
     "timestamp": 1596332633755,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "KSXLBGshyb4x",
    "outputId": "7ccb7c0a-1c74-4ea6-a71b-8ab04d2ca67f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7308, 1, 100)"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mKf0sK_xyeJ5"
   },
   "outputs": [],
   "source": [
    "## prepare the test dataset for testing of the Deep Learning model LSTM\n",
    "test_vectors_lstm = np.expand_dims(test_vectors, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 763,
     "status": "ok",
     "timestamp": 1596332643348,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "ADilQNa5yhtf",
    "outputId": "5b065c86-d383-43b6-8f62-49a42ec3de1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10546, 1, 100)"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectors_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 677,
     "status": "ok",
     "timestamp": 1596332752608,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "Tjyr3s5s2Icc",
    "outputId": "eb17f97b-31fb-4ace-cfdd-31dc28597b77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.821579456329346, 9.730830192565918)"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get the minimum and maximum values of the train vectors\n",
    "train_vectors_lstm.min(), train_vectors_lstm.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qLDcHP5y7U9j"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NyuqFX777Xwr"
   },
   "outputs": [],
   "source": [
    "## get the MinMaxScaler for normalizing the train and test vectors before training and testing the Deep Learning LSTM model\n",
    "mms = MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vPGTaAjW7bdA"
   },
   "outputs": [],
   "source": [
    "## train the MinMaxScaler object for train dataset and get the scaled features\n",
    "scaled_train_vectors_lstm = mms.fit_transform(train_vectors_lstm[:, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5QWx25i17iJx"
   },
   "outputs": [],
   "source": [
    "## prepare the scaled features to be input to the Deep Learning LSTM model\n",
    "scaled_train_vectors_lstm = np.expand_dims(scaled_train_vectors_lstm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ueieNce7poK"
   },
   "outputs": [],
   "source": [
    "## transform and prepare the scaled test features for the Deep learning LSTM model\n",
    "scaled_test_vectors_lstm = np.expand_dims(mms.transform(test_vectors_lstm[:, 0, :]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4847,
     "status": "ok",
     "timestamp": 1596332825442,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "08i3Xl7fozCk",
    "outputId": "a3ee3693-0a2c-4b16-a892-2d5487353a79"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## for preparing the Deep Learning LSTM model we use keras library\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EUrx0N8oohXg"
   },
   "outputs": [],
   "source": [
    "## create the LSTM model\n",
    "input_tensor = keras.layers.Input(shape=(1, 100))\n",
    "\n",
    "keras_model = keras.layers.LSTM(90)(input_tensor)\n",
    "\n",
    "keras_model = keras.layers.Dense(64, activation='relu')(keras_model)\n",
    "\n",
    "keras_model = keras.layers.Dense(1, activation='sigmoid')(keras_model)\n",
    "\n",
    "keras_model = keras.models.Model(inputs=[input_tensor], outputs=[keras_model])\n",
    "\n",
    "keras_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1409,
     "status": "ok",
     "timestamp": 1596332843265,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "iTXCaXb0ox5h",
    "outputId": "0eb2e967-98f6-44a5-a556-e3b3e2914f32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1, 100)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 90)                68760     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                5824      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 74,649\n",
      "Trainable params: 74,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "He998tKT27cE"
   },
   "outputs": [],
   "source": [
    "## shuffle the dataset\n",
    "## shuffling the dataset is necessary for Deep Learning based model, so that the training of the Model is proper\n",
    "## which then gives the correct metrics score\n",
    "\n",
    "train_shuffle_indices = np.random.permutation(np.arange(scaled_train_vectors_lstm.shape[0]))\n",
    "shuffled_scaled_train_vectors_lstm = scaled_train_vectors_lstm[train_shuffle_indices]\n",
    "shuffle_train_y = sub_train_y[train_shuffle_indices]\n",
    "\n",
    "test_shuffle_indices = np.random.permutation(np.arange(scaled_test_vectors_lstm.shape[0]))\n",
    "shuffled_scaled_test_vectors_lstm = scaled_test_vectors_lstm[test_shuffle_indices]\n",
    "suffle_test_y = test_y.values[test_shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 67919,
     "status": "ok",
     "timestamp": 1596333245732,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "n9V9_dbXpDYE",
    "outputId": "53f9c0c8-047a-4b4c-f984-a8e6f9d7084e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 63us/step - loss: 0.5158 - acc: 0.7556\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f279e80>\n",
      "0.6749223734839999\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 61us/step - loss: 0.5149 - acc: 0.7527\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f279470>\n",
      "0.6708488586365334\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 62us/step - loss: 0.5159 - acc: 0.7515\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f279cc0>\n",
      "0.6723111798418653\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 56us/step - loss: 0.5210 - acc: 0.7544\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f279940>\n",
      "0.672800886464371\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 61us/step - loss: 0.5162 - acc: 0.7556\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f1314e0>\n",
      "0.6642889614079521\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 59us/step - loss: 0.5146 - acc: 0.7547\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131588>\n",
      "0.6763063578653418\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 60us/step - loss: 0.5150 - acc: 0.7555\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f1317f0>\n",
      "0.6716953428149303\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 58us/step - loss: 0.5157 - acc: 0.7552\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131be0>\n",
      "0.6622051207117692\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 57us/step - loss: 0.5161 - acc: 0.7538\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131b38>\n",
      "0.6715294351630867\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 57us/step - loss: 0.5097 - acc: 0.7557\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131cc0>\n",
      "0.6743068408747748\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 58us/step - loss: 0.5148 - acc: 0.7527\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131e48>\n",
      "0.6602205201889826\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 60us/step - loss: 0.5145 - acc: 0.7570\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131710>\n",
      "0.6747846752065981\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 59us/step - loss: 0.5118 - acc: 0.7594\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0df080>\n",
      "0.6757034078547887\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 62us/step - loss: 0.5132 - acc: 0.7545\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0df240>\n",
      "0.6749694567564496\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 62us/step - loss: 0.5138 - acc: 0.7508\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0df278>\n",
      "0.6700096804831718\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 59us/step - loss: 0.5120 - acc: 0.7530\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131fd0>\n",
      "0.6627818907992791\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 60us/step - loss: 0.5149 - acc: 0.7542\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131f98>\n",
      "0.6748587501826506\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 58us/step - loss: 0.5138 - acc: 0.7601\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131c50>\n",
      "0.6723891107755752\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 61us/step - loss: 0.5131 - acc: 0.7575\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131828>\n",
      "0.6649820190606076\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 60us/step - loss: 0.5153 - acc: 0.7552\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131898>\n",
      "0.668615751789976\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 57us/step - loss: 0.5116 - acc: 0.7538\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131a90>\n",
      "0.6666180613056678\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 60us/step - loss: 0.5124 - acc: 0.7557\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131048>\n",
      "0.6702437777020116\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 57us/step - loss: 0.5113 - acc: 0.7578\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f1319e8>\n",
      "0.6745385027519362\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 56us/step - loss: 0.5096 - acc: 0.7552\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f1310b8>\n",
      "0.6690045946779667\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 58us/step - loss: 0.5138 - acc: 0.7523\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f1313c8>\n",
      "0.6703804612537139\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 60us/step - loss: 0.5105 - acc: 0.7551\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f279470>\n",
      "0.6757160919260307\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 59us/step - loss: 0.5101 - acc: 0.7567\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f279518>\n",
      "0.6244246505284691\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 59us/step - loss: 0.5135 - acc: 0.7544\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d5048>\n",
      "0.6731746099394411\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 60us/step - loss: 0.5094 - acc: 0.7564\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d5240>\n",
      "0.6746263779974997\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 59us/step - loss: 0.5142 - acc: 0.7557\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d5390>\n",
      "0.6765831750361243\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 57us/step - loss: 0.5075 - acc: 0.7560\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d54e0>\n",
      "0.6763989008491226\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 59us/step - loss: 0.5075 - acc: 0.7563\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d5630>\n",
      "0.6682540020781583\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 56us/step - loss: 0.5072 - acc: 0.7568\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d5748>\n",
      "0.6743801040702677\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 56us/step - loss: 0.5111 - acc: 0.7553\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f2798d0>\n",
      "0.6757337481531992\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 68us/step - loss: 0.5113 - acc: 0.7529\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f279ac8>\n",
      "0.6752294294806228\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 59us/step - loss: 0.5069 - acc: 0.7541\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f279470>\n",
      "0.6584479973373598\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 55us/step - loss: 0.5074 - acc: 0.7557\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f279c50>\n",
      "0.665235497540305\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 61us/step - loss: 0.5066 - acc: 0.7563\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f1314e0>\n",
      "0.6662956829509847\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 57us/step - loss: 0.5092 - acc: 0.7533\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131208>\n",
      "0.6738742633091422\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 57us/step - loss: 0.5058 - acc: 0.7575\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f1315f8>\n",
      "0.6729841459256733\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 64us/step - loss: 0.5054 - acc: 0.7559\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131908>\n",
      "0.6716089896579156\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 62us/step - loss: 0.5060 - acc: 0.7586\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131b38>\n",
      "0.674583962463267\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 54us/step - loss: 0.5116 - acc: 0.7567\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131c88>\n",
      "0.6752261823583849\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 60us/step - loss: 0.5081 - acc: 0.7574\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131e48>\n",
      "0.6756883899144382\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 57us/step - loss: 0.5067 - acc: 0.7577\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131ef0>\n",
      "0.6701863442274285\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 58us/step - loss: 0.5091 - acc: 0.7603\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131f28>\n",
      "0.6714727119964929\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 60us/step - loss: 0.5043 - acc: 0.7585\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d5860>\n",
      "0.6739765476596367\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 59us/step - loss: 0.5052 - acc: 0.7581\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d5518>\n",
      "0.6694742097316254\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 62us/step - loss: 0.5064 - acc: 0.7586\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d5438>\n",
      "0.6723105710064455\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 61us/step - loss: 0.5106 - acc: 0.7563\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d50f0>\n",
      "0.6704434757196436\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 56us/step - loss: 0.5036 - acc: 0.7567\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d5160>\n",
      "0.6654058699852256\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 60us/step - loss: 0.5051 - acc: 0.7592\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131cf8>\n",
      "0.6672562222979884\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 63us/step - loss: 0.5043 - acc: 0.7579\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131dd8>\n",
      "0.675511218807332\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 57us/step - loss: 0.5067 - acc: 0.7566\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131f28>\n",
      "0.6620686401052067\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 61us/step - loss: 0.5068 - acc: 0.7573\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131da0>\n",
      "0.6565130169012713\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 62us/step - loss: 0.5035 - acc: 0.7581\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131898>\n",
      "0.6749677317227607\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 55us/step - loss: 0.5022 - acc: 0.7594\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f1317b8>\n",
      "0.671246935528388\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 61us/step - loss: 0.5002 - acc: 0.7611\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131198>\n",
      "0.6724702888315232\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 57us/step - loss: 0.5026 - acc: 0.7589\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131588>\n",
      "0.6705583426688098\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 59us/step - loss: 0.5023 - acc: 0.7620\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131278>\n",
      "0.6739061256961018\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 61us/step - loss: 0.5054 - acc: 0.7603\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f279d30>\n",
      "0.6724711006120825\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 61us/step - loss: 0.5024 - acc: 0.7593\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f279c88>\n",
      "0.6625811780559479\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 56us/step - loss: 0.5036 - acc: 0.7589\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f279940>\n",
      "0.6738931372071502\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 62us/step - loss: 0.5053 - acc: 0.7567\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f279518>\n",
      "0.6684619193739547\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 64us/step - loss: 0.5006 - acc: 0.7603\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d5048>\n",
      "0.6754056873345996\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 56us/step - loss: 0.5003 - acc: 0.7590\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d52e8>\n",
      "0.6488145974380205\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 60us/step - loss: 0.5006 - acc: 0.7593\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d54a8>\n",
      "0.672369120679298\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 59us/step - loss: 0.5016 - acc: 0.7560\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d5358>\n",
      "0.6636854025619794\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 57us/step - loss: 0.5005 - acc: 0.7615\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d57f0>\n",
      "0.6756350153426525\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 62us/step - loss: 0.4994 - acc: 0.7593\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d5828>\n",
      "0.6705036489536149\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 62us/step - loss: 0.4989 - acc: 0.7603\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f279a58>\n",
      "0.6709666682902278\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 62us/step - loss: 0.4998 - acc: 0.7577\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f279cc0>\n",
      "0.6733886155894337\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 63us/step - loss: 0.4979 - acc: 0.7600\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f2797b8>\n",
      "0.6748891919536312\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 67us/step - loss: 0.5009 - acc: 0.7608\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f1312b0>\n",
      "0.6722005747406361\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 56us/step - loss: 0.5008 - acc: 0.7589\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f1310b8>\n",
      "0.673771877486078\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 63us/step - loss: 0.4965 - acc: 0.7633\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131748>\n",
      "0.6680073222606465\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 58us/step - loss: 0.4974 - acc: 0.7607\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131550>\n",
      "0.6788608283408829\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 58us/step - loss: 0.4982 - acc: 0.7627\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131a58>\n",
      "0.674948350461903\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 62us/step - loss: 0.4968 - acc: 0.7599\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131940>\n",
      "0.6746195793353141\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 61us/step - loss: 0.4992 - acc: 0.7575\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131b70>\n",
      "0.6780071396100206\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 61us/step - loss: 0.4995 - acc: 0.7592\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131e48>\n",
      "0.6666174524702482\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 60us/step - loss: 0.4962 - acc: 0.7608\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131eb8>\n",
      "0.6644817592908285\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 61us/step - loss: 0.4971 - acc: 0.7626\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d59b0>\n",
      "0.6600908382446057\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 60us/step - loss: 0.4970 - acc: 0.7581\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d55f8>\n",
      "0.676076826912149\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 60us/step - loss: 0.4972 - acc: 0.7571\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d56a0>\n",
      "0.6746467739840567\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 63us/step - loss: 0.4936 - acc: 0.7653\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d5588>\n",
      "0.6699858344292371\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 60us/step - loss: 0.4944 - acc: 0.7607\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d50f0>\n",
      "0.6737654847141721\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 57us/step - loss: 0.4947 - acc: 0.7618\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f0d5470>\n",
      "0.6612694421443995\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 65us/step - loss: 0.4977 - acc: 0.7579\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131c18>\n",
      "0.6709110613219035\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 58us/step - loss: 0.4937 - acc: 0.7644\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131dd8>\n",
      "0.6676452681311188\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 59us/step - loss: 0.4949 - acc: 0.7616\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131c50>\n",
      "0.6543026399103795\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 62us/step - loss: 0.4983 - acc: 0.7562\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131940>\n",
      "0.6655796924975241\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 61us/step - loss: 0.4973 - acc: 0.7641\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131be0>\n",
      "0.6731913529134804\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 57us/step - loss: 0.4954 - acc: 0.7600\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131978>\n",
      "0.6661725967236536\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 61us/step - loss: 0.4992 - acc: 0.7583\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131208>\n",
      "0.6712706801097529\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 62us/step - loss: 0.4937 - acc: 0.7625\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f131048>\n",
      "0.669106879028461\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 64us/step - loss: 0.4952 - acc: 0.7604\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f1314a8>\n",
      "0.6587568798402417\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 63us/step - loss: 0.4950 - acc: 0.7620\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f279c50>\n",
      "0.6754460734174338\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 57us/step - loss: 0.4895 - acc: 0.7661\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f279358>\n",
      "0.6358861802477553\n",
      "Epoch 1/1\n",
      "7308/7308 [==============================] - 0s 56us/step - loss: 0.4959 - acc: 0.7614\n",
      "<keras.callbacks.callbacks.History object at 0x7fb68f279940>\n",
      "0.6772487336223272\n"
     ]
    }
   ],
   "source": [
    "## train for 100 epochs and test the AUROC score at the end of each epoch\n",
    "for index in range(100):\n",
    "  print(keras_model.fit(shuffled_scaled_train_vectors_lstm, shuffle_train_y, batch_size=64))\n",
    "  print(roc_auc_score(suffle_test_y, keras_model.predict(shuffled_scaled_test_vectors_lstm)[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 73867,
     "status": "ok",
     "timestamp": 1596333348604,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "QZ-9cBrv-end",
    "outputId": "189c9986-0fca-4b49-bdc1-b2be6c25b279"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7308 samples, validate on 10546 samples\n",
      "Epoch 1/200\n",
      "7308/7308 [==============================] - 0s 54us/step - loss: 0.4858 - acc: 0.7655 - val_loss: 0.3412 - val_acc: 0.9172\n",
      "Epoch 2/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4843 - acc: 0.7660 - val_loss: 0.3127 - val_acc: 0.9244\n",
      "Epoch 3/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4814 - acc: 0.7674 - val_loss: 0.3091 - val_acc: 0.9295\n",
      "Epoch 4/200\n",
      "7308/7308 [==============================] - 0s 45us/step - loss: 0.4819 - acc: 0.7649 - val_loss: 0.3593 - val_acc: 0.8954\n",
      "Epoch 5/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4813 - acc: 0.7649 - val_loss: 0.3314 - val_acc: 0.9160\n",
      "Epoch 6/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4826 - acc: 0.7693 - val_loss: 0.3496 - val_acc: 0.9196\n",
      "Epoch 7/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4820 - acc: 0.7689 - val_loss: 0.3480 - val_acc: 0.9036\n",
      "Epoch 8/200\n",
      "7308/7308 [==============================] - 0s 53us/step - loss: 0.4806 - acc: 0.7664 - val_loss: 0.3234 - val_acc: 0.9249\n",
      "Epoch 9/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4829 - acc: 0.7660 - val_loss: 0.3149 - val_acc: 0.9257\n",
      "Epoch 10/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4793 - acc: 0.7694 - val_loss: 0.3128 - val_acc: 0.9302\n",
      "Epoch 11/200\n",
      "7308/7308 [==============================] - 0s 50us/step - loss: 0.4804 - acc: 0.7693 - val_loss: 0.3263 - val_acc: 0.9148\n",
      "Epoch 12/200\n",
      "7308/7308 [==============================] - 0s 46us/step - loss: 0.4794 - acc: 0.7679 - val_loss: 0.3639 - val_acc: 0.9061\n",
      "Epoch 13/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4804 - acc: 0.7693 - val_loss: 0.3023 - val_acc: 0.9240\n",
      "Epoch 14/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4812 - acc: 0.7692 - val_loss: 0.3385 - val_acc: 0.9066\n",
      "Epoch 15/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4801 - acc: 0.7689 - val_loss: 0.3338 - val_acc: 0.9181\n",
      "Epoch 16/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4806 - acc: 0.7701 - val_loss: 0.3317 - val_acc: 0.9160\n",
      "Epoch 17/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4796 - acc: 0.7690 - val_loss: 0.3656 - val_acc: 0.9019\n",
      "Epoch 18/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4789 - acc: 0.7678 - val_loss: 0.3160 - val_acc: 0.9194\n",
      "Epoch 19/200\n",
      "7308/7308 [==============================] - 0s 46us/step - loss: 0.4788 - acc: 0.7701 - val_loss: 0.3664 - val_acc: 0.8969\n",
      "Epoch 20/200\n",
      "7308/7308 [==============================] - 0s 50us/step - loss: 0.4793 - acc: 0.7705 - val_loss: 0.3389 - val_acc: 0.9124\n",
      "Epoch 21/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4782 - acc: 0.7697 - val_loss: 0.3657 - val_acc: 0.8882\n",
      "Epoch 22/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4788 - acc: 0.7678 - val_loss: 0.3297 - val_acc: 0.9095\n",
      "Epoch 23/200\n",
      "7308/7308 [==============================] - 0s 52us/step - loss: 0.4789 - acc: 0.7697 - val_loss: 0.3356 - val_acc: 0.9130\n",
      "Epoch 24/200\n",
      "7308/7308 [==============================] - 0s 46us/step - loss: 0.4786 - acc: 0.7716 - val_loss: 0.3283 - val_acc: 0.9148\n",
      "Epoch 25/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4767 - acc: 0.7682 - val_loss: 0.3330 - val_acc: 0.9240\n",
      "Epoch 26/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4779 - acc: 0.7677 - val_loss: 0.3342 - val_acc: 0.9141\n",
      "Epoch 27/200\n",
      "7308/7308 [==============================] - 0s 46us/step - loss: 0.4798 - acc: 0.7700 - val_loss: 0.3327 - val_acc: 0.9295\n",
      "Epoch 28/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4778 - acc: 0.7682 - val_loss: 0.2975 - val_acc: 0.9245\n",
      "Epoch 29/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4808 - acc: 0.7664 - val_loss: 0.3104 - val_acc: 0.9265\n",
      "Epoch 30/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4790 - acc: 0.7677 - val_loss: 0.3483 - val_acc: 0.8986\n",
      "Epoch 31/200\n",
      "7308/7308 [==============================] - 0s 50us/step - loss: 0.4748 - acc: 0.7722 - val_loss: 0.3223 - val_acc: 0.9199\n",
      "Epoch 32/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4768 - acc: 0.7694 - val_loss: 0.3449 - val_acc: 0.9010\n",
      "Epoch 33/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4754 - acc: 0.7696 - val_loss: 0.3117 - val_acc: 0.9217\n",
      "Epoch 34/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4779 - acc: 0.7667 - val_loss: 0.3259 - val_acc: 0.9237\n",
      "Epoch 35/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4757 - acc: 0.7703 - val_loss: 0.3042 - val_acc: 0.9141\n",
      "Epoch 36/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4775 - acc: 0.7697 - val_loss: 0.3451 - val_acc: 0.8864\n",
      "Epoch 37/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4765 - acc: 0.7750 - val_loss: 0.3407 - val_acc: 0.9028\n",
      "Epoch 38/200\n",
      "7308/7308 [==============================] - 0s 46us/step - loss: 0.4755 - acc: 0.7679 - val_loss: 0.3289 - val_acc: 0.9125\n",
      "Epoch 39/200\n",
      "7308/7308 [==============================] - 0s 45us/step - loss: 0.4759 - acc: 0.7715 - val_loss: 0.3458 - val_acc: 0.8969\n",
      "Epoch 40/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4750 - acc: 0.7724 - val_loss: 0.3498 - val_acc: 0.8975\n",
      "Epoch 41/200\n",
      "7308/7308 [==============================] - 0s 46us/step - loss: 0.4780 - acc: 0.7705 - val_loss: 0.3134 - val_acc: 0.9190\n",
      "Epoch 42/200\n",
      "7308/7308 [==============================] - 0s 50us/step - loss: 0.4757 - acc: 0.7677 - val_loss: 0.3283 - val_acc: 0.9109\n",
      "Epoch 43/200\n",
      "7308/7308 [==============================] - 0s 55us/step - loss: 0.4738 - acc: 0.7731 - val_loss: 0.3253 - val_acc: 0.9183\n",
      "Epoch 44/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4731 - acc: 0.7734 - val_loss: 0.3469 - val_acc: 0.8929\n",
      "Epoch 45/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4751 - acc: 0.7713 - val_loss: 0.2869 - val_acc: 0.9260\n",
      "Epoch 46/200\n",
      "7308/7308 [==============================] - 0s 50us/step - loss: 0.4807 - acc: 0.7711 - val_loss: 0.3067 - val_acc: 0.9203\n",
      "Epoch 47/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4772 - acc: 0.7696 - val_loss: 0.3077 - val_acc: 0.9220\n",
      "Epoch 48/200\n",
      "7308/7308 [==============================] - 0s 51us/step - loss: 0.4737 - acc: 0.7755 - val_loss: 0.3370 - val_acc: 0.9084\n",
      "Epoch 49/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4740 - acc: 0.7730 - val_loss: 0.2927 - val_acc: 0.9382\n",
      "Epoch 50/200\n",
      "7308/7308 [==============================] - 0s 50us/step - loss: 0.4802 - acc: 0.7696 - val_loss: 0.3332 - val_acc: 0.9053\n",
      "Epoch 51/200\n",
      "7308/7308 [==============================] - 0s 52us/step - loss: 0.4732 - acc: 0.7703 - val_loss: 0.3593 - val_acc: 0.8821\n",
      "Epoch 52/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4723 - acc: 0.7731 - val_loss: 0.3638 - val_acc: 0.8976\n",
      "Epoch 53/200\n",
      "7308/7308 [==============================] - 0s 51us/step - loss: 0.4730 - acc: 0.7734 - val_loss: 0.3275 - val_acc: 0.9122\n",
      "Epoch 54/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4740 - acc: 0.7687 - val_loss: 0.3699 - val_acc: 0.8888\n",
      "Epoch 55/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4730 - acc: 0.7718 - val_loss: 0.3231 - val_acc: 0.9159\n",
      "Epoch 56/200\n",
      "7308/7308 [==============================] - 0s 52us/step - loss: 0.4735 - acc: 0.7734 - val_loss: 0.3532 - val_acc: 0.8841\n",
      "Epoch 57/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4750 - acc: 0.7746 - val_loss: 0.3341 - val_acc: 0.9184\n",
      "Epoch 58/200\n",
      "7308/7308 [==============================] - 0s 55us/step - loss: 0.4735 - acc: 0.7727 - val_loss: 0.3579 - val_acc: 0.8977\n",
      "Epoch 59/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4700 - acc: 0.7737 - val_loss: 0.3225 - val_acc: 0.9117\n",
      "Epoch 60/200\n",
      "7308/7308 [==============================] - 0s 46us/step - loss: 0.4723 - acc: 0.7726 - val_loss: 0.3100 - val_acc: 0.9309\n",
      "Epoch 61/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4737 - acc: 0.7718 - val_loss: 0.3472 - val_acc: 0.9030\n",
      "Epoch 62/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4727 - acc: 0.7726 - val_loss: 0.3719 - val_acc: 0.8762\n",
      "Epoch 63/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4705 - acc: 0.7771 - val_loss: 0.3349 - val_acc: 0.9133\n",
      "Epoch 64/200\n",
      "7308/7308 [==============================] - 0s 51us/step - loss: 0.4687 - acc: 0.7760 - val_loss: 0.3370 - val_acc: 0.9076\n",
      "Epoch 65/200\n",
      "7308/7308 [==============================] - 0s 50us/step - loss: 0.4737 - acc: 0.7745 - val_loss: 0.4086 - val_acc: 0.8436\n",
      "Epoch 66/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4714 - acc: 0.7712 - val_loss: 0.3484 - val_acc: 0.9027\n",
      "Epoch 67/200\n",
      "7308/7308 [==============================] - 0s 52us/step - loss: 0.4684 - acc: 0.7746 - val_loss: 0.3390 - val_acc: 0.9098\n",
      "Epoch 68/200\n",
      "7308/7308 [==============================] - 0s 51us/step - loss: 0.4686 - acc: 0.7778 - val_loss: 0.3704 - val_acc: 0.8745\n",
      "Epoch 69/200\n",
      "7308/7308 [==============================] - 0s 46us/step - loss: 0.4671 - acc: 0.7744 - val_loss: 0.3473 - val_acc: 0.9069\n",
      "Epoch 70/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4726 - acc: 0.7760 - val_loss: 0.3707 - val_acc: 0.8752\n",
      "Epoch 71/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4695 - acc: 0.7739 - val_loss: 0.3215 - val_acc: 0.9119\n",
      "Epoch 72/200\n",
      "7308/7308 [==============================] - 0s 46us/step - loss: 0.4724 - acc: 0.7742 - val_loss: 0.3711 - val_acc: 0.8789\n",
      "Epoch 73/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4691 - acc: 0.7755 - val_loss: 0.3331 - val_acc: 0.9160\n",
      "Epoch 74/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4744 - acc: 0.7703 - val_loss: 0.3825 - val_acc: 0.8560\n",
      "Epoch 75/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4751 - acc: 0.7715 - val_loss: 0.3287 - val_acc: 0.9177\n",
      "Epoch 76/200\n",
      "7308/7308 [==============================] - 0s 51us/step - loss: 0.4733 - acc: 0.7719 - val_loss: 0.3565 - val_acc: 0.8910\n",
      "Epoch 77/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4713 - acc: 0.7730 - val_loss: 0.3200 - val_acc: 0.9134\n",
      "Epoch 78/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4675 - acc: 0.7727 - val_loss: 0.3317 - val_acc: 0.9055\n",
      "Epoch 79/200\n",
      "7308/7308 [==============================] - 0s 51us/step - loss: 0.4710 - acc: 0.7738 - val_loss: 0.3269 - val_acc: 0.9185\n",
      "Epoch 80/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4709 - acc: 0.7733 - val_loss: 0.3503 - val_acc: 0.9085\n",
      "Epoch 81/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4659 - acc: 0.7756 - val_loss: 0.4008 - val_acc: 0.8249\n",
      "Epoch 82/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4708 - acc: 0.7727 - val_loss: 0.3505 - val_acc: 0.9014\n",
      "Epoch 83/200\n",
      "7308/7308 [==============================] - 0s 45us/step - loss: 0.4741 - acc: 0.7742 - val_loss: 0.3200 - val_acc: 0.9198\n",
      "Epoch 84/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4690 - acc: 0.7734 - val_loss: 0.3684 - val_acc: 0.8912\n",
      "Epoch 85/200\n",
      "7308/7308 [==============================] - 0s 50us/step - loss: 0.4678 - acc: 0.7718 - val_loss: 0.3499 - val_acc: 0.8999\n",
      "Epoch 86/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4684 - acc: 0.7733 - val_loss: 0.3004 - val_acc: 0.9281\n",
      "Epoch 87/200\n",
      "7308/7308 [==============================] - 0s 50us/step - loss: 0.4705 - acc: 0.7745 - val_loss: 0.3577 - val_acc: 0.8915\n",
      "Epoch 88/200\n",
      "7308/7308 [==============================] - 0s 51us/step - loss: 0.4647 - acc: 0.7763 - val_loss: 0.3752 - val_acc: 0.8726\n",
      "Epoch 89/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4688 - acc: 0.7723 - val_loss: 0.3258 - val_acc: 0.9085\n",
      "Epoch 90/200\n",
      "7308/7308 [==============================] - 0s 50us/step - loss: 0.4646 - acc: 0.7760 - val_loss: 0.4033 - val_acc: 0.8408\n",
      "Epoch 91/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4647 - acc: 0.7760 - val_loss: 0.3568 - val_acc: 0.8806\n",
      "Epoch 92/200\n",
      "7308/7308 [==============================] - 0s 52us/step - loss: 0.4684 - acc: 0.7748 - val_loss: 0.2923 - val_acc: 0.9324\n",
      "Epoch 93/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4701 - acc: 0.7741 - val_loss: 0.3168 - val_acc: 0.9161\n",
      "Epoch 94/200\n",
      "7308/7308 [==============================] - 0s 50us/step - loss: 0.4674 - acc: 0.7782 - val_loss: 0.3446 - val_acc: 0.9055\n",
      "Epoch 95/200\n",
      "7308/7308 [==============================] - 0s 51us/step - loss: 0.4639 - acc: 0.7756 - val_loss: 0.3084 - val_acc: 0.9179\n",
      "Epoch 96/200\n",
      "7308/7308 [==============================] - 0s 50us/step - loss: 0.4643 - acc: 0.7772 - val_loss: 0.3710 - val_acc: 0.8562\n",
      "Epoch 97/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4629 - acc: 0.7763 - val_loss: 0.2931 - val_acc: 0.9251\n",
      "Epoch 98/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4661 - acc: 0.7748 - val_loss: 0.3520 - val_acc: 0.8946\n",
      "Epoch 99/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4628 - acc: 0.7763 - val_loss: 0.3190 - val_acc: 0.9143\n",
      "Epoch 100/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4627 - acc: 0.7779 - val_loss: 0.3586 - val_acc: 0.8954\n",
      "Epoch 101/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4632 - acc: 0.7768 - val_loss: 0.3166 - val_acc: 0.9242\n",
      "Epoch 102/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4655 - acc: 0.7783 - val_loss: 0.3197 - val_acc: 0.9200\n",
      "Epoch 103/200\n",
      "7308/7308 [==============================] - 0s 51us/step - loss: 0.4659 - acc: 0.7716 - val_loss: 0.3905 - val_acc: 0.8544\n",
      "Epoch 104/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4647 - acc: 0.7741 - val_loss: 0.3307 - val_acc: 0.9141\n",
      "Epoch 105/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4681 - acc: 0.7718 - val_loss: 0.3224 - val_acc: 0.9070\n",
      "Epoch 106/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4612 - acc: 0.7770 - val_loss: 0.3351 - val_acc: 0.9075\n",
      "Epoch 107/200\n",
      "7308/7308 [==============================] - 0s 46us/step - loss: 0.4617 - acc: 0.7802 - val_loss: 0.3309 - val_acc: 0.9055\n",
      "Epoch 108/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4655 - acc: 0.7760 - val_loss: 0.3383 - val_acc: 0.8983\n",
      "Epoch 109/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4620 - acc: 0.7770 - val_loss: 0.3540 - val_acc: 0.8884\n",
      "Epoch 110/200\n",
      "7308/7308 [==============================] - 0s 56us/step - loss: 0.4626 - acc: 0.7801 - val_loss: 0.3087 - val_acc: 0.9173\n",
      "Epoch 111/200\n",
      "7308/7308 [==============================] - 0s 51us/step - loss: 0.4618 - acc: 0.7787 - val_loss: 0.3594 - val_acc: 0.8903\n",
      "Epoch 112/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4624 - acc: 0.7767 - val_loss: 0.3599 - val_acc: 0.9031\n",
      "Epoch 113/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4656 - acc: 0.7775 - val_loss: 0.3634 - val_acc: 0.8866\n",
      "Epoch 114/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4581 - acc: 0.7790 - val_loss: 0.3338 - val_acc: 0.9005\n",
      "Epoch 115/200\n",
      "7308/7308 [==============================] - 0s 51us/step - loss: 0.4611 - acc: 0.7785 - val_loss: 0.2993 - val_acc: 0.9317\n",
      "Epoch 116/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4610 - acc: 0.7772 - val_loss: 0.3144 - val_acc: 0.9253\n",
      "Epoch 117/200\n",
      "7308/7308 [==============================] - 0s 50us/step - loss: 0.4589 - acc: 0.7812 - val_loss: 0.3420 - val_acc: 0.9099\n",
      "Epoch 118/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4620 - acc: 0.7760 - val_loss: 0.2835 - val_acc: 0.9286\n",
      "Epoch 119/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4672 - acc: 0.7786 - val_loss: 0.3143 - val_acc: 0.9170\n",
      "Epoch 120/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4627 - acc: 0.7752 - val_loss: 0.3848 - val_acc: 0.8503\n",
      "Epoch 121/200\n",
      "7308/7308 [==============================] - 0s 46us/step - loss: 0.4597 - acc: 0.7748 - val_loss: 0.3618 - val_acc: 0.8846\n",
      "Epoch 122/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4589 - acc: 0.7781 - val_loss: 0.3745 - val_acc: 0.8770\n",
      "Epoch 123/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4586 - acc: 0.7761 - val_loss: 0.3545 - val_acc: 0.8786\n",
      "Epoch 124/200\n",
      "7308/7308 [==============================] - 0s 46us/step - loss: 0.4571 - acc: 0.7798 - val_loss: 0.3416 - val_acc: 0.8994\n",
      "Epoch 125/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4607 - acc: 0.7775 - val_loss: 0.3137 - val_acc: 0.9225\n",
      "Epoch 126/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4574 - acc: 0.7794 - val_loss: 0.3631 - val_acc: 0.8786\n",
      "Epoch 127/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4615 - acc: 0.7796 - val_loss: 0.3433 - val_acc: 0.8918\n",
      "Epoch 128/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4589 - acc: 0.7767 - val_loss: 0.3248 - val_acc: 0.9110\n",
      "Epoch 129/200\n",
      "7308/7308 [==============================] - 0s 50us/step - loss: 0.4594 - acc: 0.7800 - val_loss: 0.3655 - val_acc: 0.8757\n",
      "Epoch 130/200\n",
      "7308/7308 [==============================] - 0s 52us/step - loss: 0.4585 - acc: 0.7798 - val_loss: 0.3381 - val_acc: 0.8892\n",
      "Epoch 131/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4589 - acc: 0.7820 - val_loss: 0.3677 - val_acc: 0.8786\n",
      "Epoch 132/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4550 - acc: 0.7826 - val_loss: 0.3840 - val_acc: 0.8584\n",
      "Epoch 133/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4577 - acc: 0.7819 - val_loss: 0.3253 - val_acc: 0.9101\n",
      "Epoch 134/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4567 - acc: 0.7813 - val_loss: 0.3399 - val_acc: 0.8962\n",
      "Epoch 135/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4575 - acc: 0.7805 - val_loss: 0.3662 - val_acc: 0.8843\n",
      "Epoch 136/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4569 - acc: 0.7828 - val_loss: 0.3668 - val_acc: 0.8756\n",
      "Epoch 137/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4602 - acc: 0.7801 - val_loss: 0.3215 - val_acc: 0.9178\n",
      "Epoch 138/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4584 - acc: 0.7779 - val_loss: 0.3806 - val_acc: 0.8694\n",
      "Epoch 139/200\n",
      "7308/7308 [==============================] - 0s 52us/step - loss: 0.4575 - acc: 0.7797 - val_loss: 0.3534 - val_acc: 0.8816\n",
      "Epoch 140/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4532 - acc: 0.7849 - val_loss: 0.3312 - val_acc: 0.9115\n",
      "Epoch 141/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4512 - acc: 0.7831 - val_loss: 0.3240 - val_acc: 0.9092\n",
      "Epoch 142/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4540 - acc: 0.7791 - val_loss: 0.3315 - val_acc: 0.9003\n",
      "Epoch 143/200\n",
      "7308/7308 [==============================] - 0s 46us/step - loss: 0.4534 - acc: 0.7770 - val_loss: 0.3102 - val_acc: 0.9185\n",
      "Epoch 144/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4541 - acc: 0.7820 - val_loss: 0.3340 - val_acc: 0.9079\n",
      "Epoch 145/200\n",
      "7308/7308 [==============================] - 0s 53us/step - loss: 0.4574 - acc: 0.7835 - val_loss: 0.3249 - val_acc: 0.9020\n",
      "Epoch 146/200\n",
      "7308/7308 [==============================] - 0s 50us/step - loss: 0.4535 - acc: 0.7808 - val_loss: 0.4003 - val_acc: 0.8590\n",
      "Epoch 147/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4543 - acc: 0.7833 - val_loss: 0.3723 - val_acc: 0.8677\n",
      "Epoch 148/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4534 - acc: 0.7800 - val_loss: 0.3369 - val_acc: 0.9021\n",
      "Epoch 149/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4532 - acc: 0.7867 - val_loss: 0.3313 - val_acc: 0.9100\n",
      "Epoch 150/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4546 - acc: 0.7812 - val_loss: 0.3288 - val_acc: 0.8978\n",
      "Epoch 151/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4547 - acc: 0.7793 - val_loss: 0.4227 - val_acc: 0.8286\n",
      "Epoch 152/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4547 - acc: 0.7828 - val_loss: 0.3525 - val_acc: 0.8880\n",
      "Epoch 153/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4552 - acc: 0.7833 - val_loss: 0.3285 - val_acc: 0.9180\n",
      "Epoch 154/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4559 - acc: 0.7778 - val_loss: 0.4052 - val_acc: 0.8446\n",
      "Epoch 155/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4543 - acc: 0.7804 - val_loss: 0.4093 - val_acc: 0.8349\n",
      "Epoch 156/200\n",
      "7308/7308 [==============================] - 0s 50us/step - loss: 0.4520 - acc: 0.7808 - val_loss: 0.3310 - val_acc: 0.9065\n",
      "Epoch 157/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4514 - acc: 0.7848 - val_loss: 0.3948 - val_acc: 0.8668\n",
      "Epoch 158/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4536 - acc: 0.7808 - val_loss: 0.3994 - val_acc: 0.8484\n",
      "Epoch 159/200\n",
      "7308/7308 [==============================] - 0s 50us/step - loss: 0.4547 - acc: 0.7830 - val_loss: 0.3824 - val_acc: 0.8700\n",
      "Epoch 160/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4490 - acc: 0.7853 - val_loss: 0.3193 - val_acc: 0.9096\n",
      "Epoch 161/200\n",
      "7308/7308 [==============================] - 0s 45us/step - loss: 0.4554 - acc: 0.7807 - val_loss: 0.3507 - val_acc: 0.8938\n",
      "Epoch 162/200\n",
      "7308/7308 [==============================] - 0s 50us/step - loss: 0.4478 - acc: 0.7860 - val_loss: 0.4035 - val_acc: 0.8382\n",
      "Epoch 163/200\n",
      "7308/7308 [==============================] - 0s 51us/step - loss: 0.4507 - acc: 0.7815 - val_loss: 0.3380 - val_acc: 0.8924\n",
      "Epoch 164/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4549 - acc: 0.7852 - val_loss: 0.4094 - val_acc: 0.8442\n",
      "Epoch 165/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4572 - acc: 0.7793 - val_loss: 0.3536 - val_acc: 0.8904\n",
      "Epoch 166/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4490 - acc: 0.7815 - val_loss: 0.3253 - val_acc: 0.9060\n",
      "Epoch 167/200\n",
      "7308/7308 [==============================] - 0s 50us/step - loss: 0.4482 - acc: 0.7837 - val_loss: 0.3484 - val_acc: 0.8895\n",
      "Epoch 168/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4507 - acc: 0.7815 - val_loss: 0.3341 - val_acc: 0.9143\n",
      "Epoch 169/200\n",
      "7308/7308 [==============================] - 0s 45us/step - loss: 0.4478 - acc: 0.7838 - val_loss: 0.3234 - val_acc: 0.9039\n",
      "Epoch 170/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4468 - acc: 0.7879 - val_loss: 0.3410 - val_acc: 0.8993\n",
      "Epoch 171/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4497 - acc: 0.7819 - val_loss: 0.3484 - val_acc: 0.8826\n",
      "Epoch 172/200\n",
      "7308/7308 [==============================] - 0s 47us/step - loss: 0.4525 - acc: 0.7812 - val_loss: 0.3644 - val_acc: 0.8730\n",
      "Epoch 173/200\n",
      "7308/7308 [==============================] - 0s 48us/step - loss: 0.4475 - acc: 0.7856 - val_loss: 0.4048 - val_acc: 0.8507\n",
      "Epoch 174/200\n",
      "7308/7308 [==============================] - 0s 49us/step - loss: 0.4502 - acc: 0.7820 - val_loss: 0.3510 - val_acc: 0.8952\n",
      "Epoch 175/200\n",
      "7308/7308 [==============================] - 0s 55us/step - loss: 0.4525 - acc: 0.7822 - val_loss: 0.3635 - val_acc: 0.8870\n",
      "Epoch 176/200\n",
      "7308/7308 [==============================] - 0s 58us/step - loss: 0.4526 - acc: 0.7812 - val_loss: 0.3023 - val_acc: 0.9193\n",
      "Epoch 177/200\n",
      "7308/7308 [==============================] - 0s 54us/step - loss: 0.4482 - acc: 0.7826 - val_loss: 0.4024 - val_acc: 0.8431\n",
      "Epoch 178/200\n",
      "7308/7308 [==============================] - 0s 58us/step - loss: 0.4531 - acc: 0.7813 - val_loss: 0.3733 - val_acc: 0.8625\n",
      "Epoch 179/200\n",
      "7308/7308 [==============================] - 0s 56us/step - loss: 0.4509 - acc: 0.7820 - val_loss: 0.3499 - val_acc: 0.8962\n",
      "Epoch 180/200\n",
      "7308/7308 [==============================] - 0s 51us/step - loss: 0.4477 - acc: 0.7843 - val_loss: 0.3463 - val_acc: 0.8948\n",
      "Epoch 181/200\n",
      "7308/7308 [==============================] - 0s 55us/step - loss: 0.4554 - acc: 0.7820 - val_loss: 0.3872 - val_acc: 0.8641\n",
      "Epoch 182/200\n",
      "7308/7308 [==============================] - 0s 51us/step - loss: 0.4482 - acc: 0.7856 - val_loss: 0.3370 - val_acc: 0.8986\n",
      "Epoch 183/200\n",
      "7308/7308 [==============================] - 0s 52us/step - loss: 0.4466 - acc: 0.7846 - val_loss: 0.3770 - val_acc: 0.8776\n",
      "Epoch 184/200\n",
      "7308/7308 [==============================] - 0s 52us/step - loss: 0.4470 - acc: 0.7871 - val_loss: 0.3281 - val_acc: 0.9087\n",
      "Epoch 185/200\n",
      "7308/7308 [==============================] - 0s 51us/step - loss: 0.4497 - acc: 0.7842 - val_loss: 0.3156 - val_acc: 0.9139\n",
      "Epoch 186/200\n",
      "7308/7308 [==============================] - 0s 54us/step - loss: 0.4469 - acc: 0.7876 - val_loss: 0.3628 - val_acc: 0.8916\n",
      "Epoch 187/200\n",
      "7308/7308 [==============================] - 0s 54us/step - loss: 0.4479 - acc: 0.7839 - val_loss: 0.4371 - val_acc: 0.8485\n",
      "Epoch 188/200\n",
      "7308/7308 [==============================] - 0s 53us/step - loss: 0.4471 - acc: 0.7828 - val_loss: 0.3805 - val_acc: 0.8570\n",
      "Epoch 189/200\n",
      "7308/7308 [==============================] - 0s 55us/step - loss: 0.4455 - acc: 0.7864 - val_loss: 0.3207 - val_acc: 0.9061\n",
      "Epoch 190/200\n",
      "7308/7308 [==============================] - 0s 51us/step - loss: 0.4478 - acc: 0.7824 - val_loss: 0.3780 - val_acc: 0.8745\n",
      "Epoch 191/200\n",
      "7308/7308 [==============================] - 0s 59us/step - loss: 0.4448 - acc: 0.7891 - val_loss: 0.3790 - val_acc: 0.8737\n",
      "Epoch 192/200\n",
      "7308/7308 [==============================] - 0s 53us/step - loss: 0.4439 - acc: 0.7912 - val_loss: 0.3283 - val_acc: 0.9031\n",
      "Epoch 193/200\n",
      "7308/7308 [==============================] - 0s 53us/step - loss: 0.4441 - acc: 0.7839 - val_loss: 0.4065 - val_acc: 0.8512\n",
      "Epoch 194/200\n",
      "7308/7308 [==============================] - 0s 54us/step - loss: 0.4451 - acc: 0.7902 - val_loss: 0.3658 - val_acc: 0.8778\n",
      "Epoch 195/200\n",
      "7308/7308 [==============================] - 0s 53us/step - loss: 0.4422 - acc: 0.7891 - val_loss: 0.3667 - val_acc: 0.8745\n",
      "Epoch 196/200\n",
      "7308/7308 [==============================] - 0s 54us/step - loss: 0.4423 - acc: 0.7845 - val_loss: 0.3294 - val_acc: 0.8978\n",
      "Epoch 197/200\n",
      "7308/7308 [==============================] - 0s 52us/step - loss: 0.4437 - acc: 0.7883 - val_loss: 0.3629 - val_acc: 0.8752\n",
      "Epoch 198/200\n",
      "7308/7308 [==============================] - 0s 53us/step - loss: 0.4437 - acc: 0.7861 - val_loss: 0.4359 - val_acc: 0.8278\n",
      "Epoch 199/200\n",
      "7308/7308 [==============================] - 0s 58us/step - loss: 0.4538 - acc: 0.7774 - val_loss: 0.3481 - val_acc: 0.8825\n",
      "Epoch 200/200\n",
      "7308/7308 [==============================] - 0s 54us/step - loss: 0.4460 - acc: 0.7831 - val_loss: 0.3510 - val_acc: 0.9011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb68f24f2e8>"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train for yet another 200 epochs and test the loss and accuracy for the test dataset at the end of each epoch\n",
    "keras_model.fit(shuffled_scaled_train_vectors_lstm, shuffle_train_y, batch_size=256, epochs=200, validation_data=(shuffled_scaled_test_vectors_lstm, suffle_test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1288,
     "status": "ok",
     "timestamp": 1596333377627,
     "user": {
      "displayName": "Tanisha Bhayani",
      "photoUrl": "",
      "userId": "03093037226242090836"
     },
     "user_tz": -330
    },
    "id": "3QG0vyzl-vkJ",
    "outputId": "b1d9194e-1c6c-4686-a045-ff48cc8e26a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6721115832968032"
      ]
     },
     "execution_count": 100,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we obtained the the auroc score of the keras Deep Learning based LSTM model\n",
    "roc_auc_score(suffle_test_y, keras_model.predict(shuffled_scaled_test_vectors_lstm)[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dxaWbzD6pXhn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM3Yc21zsHOeZ73+DilPlKm",
   "collapsed_sections": [],
   "mount_file_id": "1qW1E2FnQOR-yllNQt-GKNhe5g0-Fumx3",
   "name": "ML4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
